{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# February 24th 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI and Human Rights\n",
    "\n",
    "Megan Price <br>\n",
    "Executive Director <br>\n",
    "[Human Rights Data Analysis Group (HRDAG)](https://hrdag.org/)\n",
    "\n",
    "Who we are and we do\n",
    "\n",
    "What are human rights?\n",
    "\n",
    "Human rights stories tell about the worst events that anyone can experience...We are \n",
    "morally obligated to do the best work that technically possible, so that the victim's \n",
    "story is told. - Patrick Bell\n",
    "\n",
    "\n",
    "*Post-truth?* \n",
    "\n",
    "People and institutions that commit violence nearly always lie about it. The lies are often grotesque and easily disproven. \n",
    "\n",
    "**Speak Truth to Power**\n",
    "\n",
    "Adversely environment, in court and outside.\n",
    "\n",
    "What is AI for human rights?\n",
    "\n",
    "  -  HRDAG case studies\n",
    "  -  Other cases studies\n",
    "\n",
    "What could go wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML/AI at HRDAG\n",
    "\n",
    "###  Identifying individual victims report across multiple sources or lists\n",
    "   Entity resolution/linkage. Public data from Syria. Record linkage problem. \n",
    "\n",
    "### Indenifying geogrpahic areas likely to contain undiscoverd graves\n",
    "Finding hidden graves in Mexico\n",
    "\n",
    "2455 municipios in Mexico\n",
    "\n",
    "List ~75 municipios in which graves have been found\n",
    "\n",
    "List of ~75 municipios confident do not contain graves\n",
    "\n",
    "Random forest model, models provide partners interesting new tool. Dangerous for families of victims to adovacte, little bit safer.\n",
    "Distance science for advocates and partners. \n",
    "\n",
    "### Evaluing performance of models in active use in US criminal justice system.\n",
    "\n",
    "**Predictive Policing  Reinforces Police Bias** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why are ML Models wrong?\n",
    "\n",
    "1. ML models are always a little wrong - otherwise they're overfit\n",
    "1.  Do have data that is representative of the population to which we intend to apply the model? Or is systematically hidden?\n",
    "1.  In real-world social data there is nearly always a relationship between the observability of the data and the question we're trying to answer\n",
    "1.  Biased models - inlcuding visualization and maps - are often the result of unrepresentative data\n",
    "\n",
    "### What's the cost of begin wrong?\n",
    "*  Do we waste resources? Or do we affect people?\n",
    "\n",
    "False positives, false negatives. \n",
    "\n",
    "In predictive policing, a false positive means a neighborhood can be systematically overpoliced., A false negative means the police fail to resond quickly to real crime.\n",
    "\n",
    "Costs being brone by the vendor or model creator not the people impacted\n",
    "\n",
    "Improvement over status quo\n",
    "\n",
    "### Adventures in Predictive Modeling\n",
    "Good use Suicide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
